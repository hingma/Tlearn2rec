{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCfT7kogFMGE"
      },
      "source": [
        "# GNN Training for MILP Problems\n",
        "\n",
        "This notebook implements the training of a Graph Neural Network (GNN) for MILP problems. It includes:\n",
        "1. Setup and installation of required packages\n",
        "2. Data loading and preprocessing\n",
        "3. Model training with different configurations\n",
        "4. Visualization of training dynamics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avjaOCWwFMGJ"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive to access your data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "%pip install torch-geometric\n",
        "%pip install matplotlib numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "kggXtbiSFMGM"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Set the path to your project directory\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Tlearn2rec'  # Modify this path as needed\n",
        "sys.path.append(PROJECT_DIR)\n",
        "\n",
        "# Import project modules\n",
        "from gnn_model import GCNPolicy\n",
        "import config\n",
        "from visualization import TrainingVisualizer\n",
        "\n",
        "# Modify GCNPolicy's forward method (assuming gnn_model.py contains the GCNPolicy class)\n",
        "# This is a placeholder and assumes you have a GCNPolicy class in gnn_model.py\n",
        "# You will need to manually apply this change to your gnn_model.py file.\n",
        "# For demonstration, I'll show the intended change here:\n",
        "# class GCNPolicy(nn.Module):\n",
        "#     ...\n",
        "#     def forward(self, inputs, v_labels=None):\n",
        "#         constraint_features, edge_indices, edge_features, variable_features = inputs\n",
        "#         ... # Rest of the forward method logic using these 4 inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gexQzshKFMGQ"
      },
      "outputs": [],
      "source": [
        "# Define dataset and model classes\n",
        "class MILPDataset(Dataset):\n",
        "    def __init__(self, sample_files):\n",
        "        self.sample_files = sample_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.load(self.sample_files[idx], weights_only=False)\n",
        "        return data\n",
        "\n",
        "class SupervisedContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        labels_matrix = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
        "        labels_matrix.fill_diagonal_(False)\n",
        "\n",
        "        if not labels_matrix.any():\n",
        "            return torch.tensor(0.0, device=embeddings.device)\n",
        "\n",
        "        sim_matrix = torch.matmul(embeddings, embeddings.T)\n",
        "        logits_mask = torch.ones_like(sim_matrix).fill_diagonal_(0)\n",
        "\n",
        "        exp_sim = torch.exp(sim_matrix / self.temperature)\n",
        "        log_prob = (sim_matrix / self.temperature) - torch.log((exp_sim * logits_mask).sum(1, keepdim=True))\n",
        "\n",
        "        mean_log_prob_pos = (labels_matrix * log_prob).sum(1) / labels_matrix.sum(1).clamp(min=1)\n",
        "        loss = -mean_log_prob_pos\n",
        "\n",
        "        has_positives = labels_matrix.sum(1) > 0\n",
        "        loss = loss[has_positives].mean()\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "DZ834vx0FMGQ"
      },
      "outputs": [],
      "source": [
        "def process(model, dataloader, criterion, optimizer=None, scaler=None, device='cpu', epoch=None, phase='train'):\n",
        "    mean_loss = 0\n",
        "    n_samples_processed = 0\n",
        "    is_train = optimizer is not None\n",
        "\n",
        "    if is_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    for batch in dataloader:\n",
        "        # Move the batch to the specified device\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Access data directly from the Batch object\n",
        "        c = batch['constraint'].x\n",
        "        ei = batch[('constraint', 'includes', 'variable')].edge_index\n",
        "        ev = batch[('constraint', 'includes', 'variable')].edge_attr\n",
        "        v = batch['variable'].x\n",
        "        v_labels = batch['variable'].y\n",
        "        # n_cs and n_vs are not directly available in the batched HeteroData object in this form.\n",
        "        # You might need to adjust your model or data loading/processing\n",
        "        # to handle variable numbers of constraints/variables per graph in a batch.\n",
        "        # For now, I will remove them from the input to the model call.\n",
        "        # If n_cs and n_vs are needed, you'll need to find a way to include them\n",
        "        # in the HeteroData object or calculate them during batching.\n",
        "\n",
        "        model_input = (c, ei, ev, v) # Adjusted model input\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with autocast(device_type=\"cuda\", enabled=(scaler is not None)):\n",
        "            # Assuming the model can handle the adjusted input and returns\n",
        "            # proj_embeddings and fg_labels based on the variable node features.\n",
        "            proj_embeddings, fg_labels = model(model_input, v_labels)\n",
        "\n",
        "\n",
        "            if proj_embeddings is not None and fg_labels is not None:\n",
        "                loss = criterion(proj_embeddings, fg_labels)\n",
        "            else:\n",
        "                loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "        if is_train:\n",
        "            if scaler is not None:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # The number of samples processed in a batch is the number of graphs in the batch.\n",
        "        # When using torch_geometric.data.Batch, the number of graphs is available\n",
        "        # as batch.num_graphs if you are batching multiple graphs.\n",
        "        # If the DataLoader is configured to batch multiple graphs, use batch.num_graphs.\n",
        "        # If you are processing one graph per batch (batch_size=1), n_samples_processed += 1.\n",
        "        # Assuming you are batching multiple graphs:\n",
        "        mean_loss += loss.item() * batch.num_graphs\n",
        "        n_samples_processed += batch.num_graphs\n",
        "\n",
        "\n",
        "    if n_samples_processed > 0:\n",
        "        mean_loss /= n_samples_processed\n",
        "\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "9m-3QGYLFMGR"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, scaler, device,\n",
        "                running_dir, max_epochs, early_stopping, patience, visualizer):\n",
        "    best_loss = np.inf\n",
        "    plateau_count = 0\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    for epoch in range(max_epochs + 1):\n",
        "        print(f\"Epoch {epoch}...\")\n",
        "\n",
        "        # Train\n",
        "        train_loss = process(model, train_loader, criterion, optimizer, scaler, device, epoch, 'train')\n",
        "        print(f\"Train Loss: {train_loss:0.3f}\")\n",
        "\n",
        "        # Validate\n",
        "        valid_loss = process(model, valid_loader, criterion, None, scaler, device, epoch, 'valid')\n",
        "        print(f\"Valid Loss: {valid_loss:0.3f}\")\n",
        "\n",
        "        # Update visualization\n",
        "        visualizer.update(epoch, train_loss, valid_loss, current_lr)\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            plateau_count = 0\n",
        "            best_loss = valid_loss\n",
        "            model.save_state(running_dir / 'best_params.pkl')\n",
        "            print(\"Best model so far\")\n",
        "        else:\n",
        "            plateau_count += 1\n",
        "            if plateau_count >= early_stopping:\n",
        "                print(f\"{plateau_count} epochs without improvement, early stopping\")\n",
        "                break\n",
        "            if plateau_count % patience == 0:\n",
        "                current_lr *= 0.2\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = current_lr\n",
        "                print(f\"Decreasing learning rate to {current_lr:.1e}\")\n",
        "\n",
        "        # Plot progress\n",
        "        if epoch % 10 == 0:\n",
        "            visualizer.plot_training_curves()\n",
        "            plt.show()\n",
        "            visualizer.plot_learning_rate()\n",
        "            plt.show()\n",
        "            visualizer.save_history()\n",
        "\n",
        "    return best_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QPH539SFMGR"
      },
      "source": [
        "## Training Configuration\n",
        "\n",
        "Set up the training parameters and experiment configuration below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GksZ6FxzFMGT",
        "outputId": "d3d8fc7f-0fba-49fa-bc72-c2685ec6134e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Training configuration\n",
        "problem = 'facilities'  # or 'osif'\n",
        "experiment_name = 'experiment_1'\n",
        "train_size = 1.0  # fraction of training data to use\n",
        "max_epochs = 1000\n",
        "\n",
        "# Load parameters from config\n",
        "train_params = config.TRAIN_PARAMS.copy()\n",
        "model_params = config.MODEL_PARAMS\n",
        "train_params['max_epochs'] = max_epochs\n",
        "\n",
        "# Setup directories\n",
        "running_dir = Path(PROJECT_DIR) / 'models' / problem / 'GCNPolicy' / experiment_name\n",
        "os.makedirs(running_dir, exist_ok=True)\n",
        "\n",
        "# Initialize visualizer\n",
        "visualizer = TrainingVisualizer(running_dir)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize GradScaler for mixed precision training\n",
        "scaler = GradScaler(device='cuda') if device.type == 'cuda' else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOjH0yARFMGU",
        "outputId": "4295864f-98f6-456e-b2c2-396b32b92837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare data\n",
        "train_files = list((Path(PROJECT_DIR) / 'data/processed' / problem / 'train').glob('*.pt'))\n",
        "valid_files = list((Path(PROJECT_DIR) / 'data/processed' / problem / 'valid').glob('*.pt'))\n",
        "\n",
        "train_files = [str(x) for x in train_files]\n",
        "valid_files = [str(x) for x in valid_files]\n",
        "\n",
        "if train_size < 1.0:\n",
        "    n_train = int(len(train_files) * train_size)\n",
        "    train_files = train_files[:n_train]\n",
        "    print(f\"Using {n_train} training files\")\n",
        "\n",
        "train_dataset = MILPDataset(train_files)\n",
        "valid_dataset = MILPDataset(valid_files)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_params['batch_size'],\n",
        "                         shuffle=True, collate_fn=collate_fn,\n",
        "                         num_workers=train_params['num_workers'],\n",
        "                         pin_memory=True)\n",
        "\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=train_params['valid_batch_size'],\n",
        "                         shuffle=False, collate_fn=collate_fn,\n",
        "                         num_workers=train_params['num_workers'],\n",
        "                         pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "3iCz9iV4FMGV",
        "outputId": "04f88e15-3bc1-4b18-b47b-2ee3ad7e24a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 6, got 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1779682192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m best_loss = train_model(model, train_loader, valid_loader, criterion, optimizer, scaler, \n\u001b[0m\u001b[1;32m     10\u001b[0m                        \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'early_stopping'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                        train_params['patience'], visualizer)\n",
            "\u001b[0;32m/tmp/ipython-input-3451390442.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, criterion, optimizer, scaler, device, running_dir, max_epochs, early_stopping, patience, visualizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {train_loss:0.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-403209854.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(model, dataloader, criterion, optimizer, scaler, device, epoch, phase)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Assuming the model can handle the adjusted input and returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# proj_embeddings and fg_labels based on the variable node features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mproj_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gnn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, v_labels)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mvariable_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mall\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mconstraint_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cons_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_vars_per_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mreversed_edge_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
          ]
        }
      ],
      "source": [
        "# Initialize model and training components\n",
        "model = GCNPolicy(emb_size=model_params['emb_size'])\n",
        "model.to(device)\n",
        "\n",
        "criterion = SupervisedContrastiveLoss(temperature=train_params['temperature']).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=train_params['lr'])\n",
        "\n",
        "# Train the model\n",
        "best_loss = train_model(model, train_loader, valid_loader, criterion, optimizer, scaler,\n",
        "                       device, running_dir, max_epochs, train_params['early_stopping'],\n",
        "                       train_params['patience'], visualizer)\n",
        "\n",
        "# Load best model and compute final validation loss\n",
        "model.restore_state(running_dir / 'best_params.pkl')\n",
        "final_valid_loss = process(model, valid_loader, criterion, None, scaler, device)\n",
        "print(f\"Best validation loss: {final_valid_loss:0.3f}\")\n",
        "\n",
        "# Final visualization\n",
        "visualizer.plot_training_curves(f\"Final Training Curves - {experiment_name}\")\n",
        "plt.show()\n",
        "visualizer.plot_learning_rate()\n",
        "plt.show()\n",
        "visualizer.save_history()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d688dc",
        "outputId": "8652e38c-4047-470f-a390-fd0929f4ea20"
      },
      "source": [
        "# Load and inspect a single data sample\n",
        "sample_data = torch.load(train_files[0], weights_only=False)\n",
        "print(sample_data)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  constraint={ x=[160, 263] },\n",
            "  variable={\n",
            "    x=[240, 262],\n",
            "    var_names=[240],\n",
            "    y=[240],\n",
            "    train_mask=[240],\n",
            "  },\n",
            "  (constraint, includes, variable)={\n",
            "    edge_index=[2, 640],\n",
            "    edge_attr=[640, 1],\n",
            "  },\n",
            "  (variable, in, constraint)={\n",
            "    edge_index=[2, 640],\n",
            "    edge_attr=[640, 1],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbe24fd8"
      },
      "source": [
        "from torch_geometric.data import Batch\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Batch HeteroData objects using torch_geometric's Batch\n",
        "    return Batch.from_data_list(batch)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyJ3C5cgFMGV"
      },
      "source": [
        "## Experiment with Different Configurations\n",
        "\n",
        "You can run multiple experiments with different configurations by modifying the parameters in the cells above. For example:\n",
        "\n",
        "1. Try different training data sizes:\n",
        "```python\n",
        "train_size = 0.5  # Use 50% of training data\n",
        "```\n",
        "\n",
        "2. Try different numbers of epochs:\n",
        "```python\n",
        "max_epochs = 500  # Train for 500 epochs\n",
        "```\n",
        "\n",
        "3. Try different learning rates:\n",
        "```python\n",
        "train_params['lr'] = 0.0005  # Use a different learning rate\n",
        "```\n",
        "\n",
        "Remember to give each experiment a unique name to keep track of results:\n",
        "```python\n",
        "experiment_name = 'experiment_2_half_data'\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}