{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrrTRdu5QY3x"
      },
      "source": [
        "\n",
        "#GNN Node Clustering - Google Colab Notebook\n",
        "\n",
        "Complete implementation for training GNNs to cluster graph nodes.\n",
        "Ready to run on Google Colab with GPU support.\n",
        "\n",
        "To use:\n",
        "1. Copy this entire file\n",
        "2. Open Google Colab (colab.research.google.com)\n",
        "3. Create new notebook\n",
        "4. Paste code into cells as indicated below\n",
        "5. Run cells in order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe7vj8aQal01",
        "outputId": "1e3a55e1-4bf6-4253-875f-34dff9f89d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "gyO3GRM3JZSV"
      },
      "outputs": [],
      "source": [
        "# --- 指定数据文件储存地址 ---\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Project Root ---\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/GNN-MILP\")\n",
        "\n",
        "# --- Base Directories ---\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
        "\n",
        "PROBLEM = 'osif'\n",
        "# PROBLEM = 'facilities'\n",
        "\n",
        "# --- Data Subdirectories ---\n",
        "RAW_DATA_DIR = DATA_DIR / PROBLEM /\"raw\"\n",
        "MPS_DATA_DIR = DATA_DIR / PROBLEM / \"mps\"\n",
        "PROCESSED_DATA_DIR = DATA_DIR / PROBLEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljz4eePMQvV3"
      },
      "source": [
        "# Install PyTorch Geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "collapsed": true,
        "id": "JcR7kQ7pSv1N",
        "outputId": "e300fa49-8b41-48ac-e2ff-5d2a64b1a630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torch_geometric\n",
        "!pip install scikit-learn matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uluzhac0Qt9t",
        "outputId": "8adbfe9f-dbcb-4c29-810c-7f04cd5442c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
        "import numpy as np\n",
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6fGANjPRCpZ"
      },
      "source": [
        "# CELL 3: GNN Model Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_O7GcplRJAM",
        "outputId": "9d4c4931-2b97-4ec9-85df-5d16c132f0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GNN architectures defined: GCN, GAT, SAGE\n"
          ]
        }
      ],
      "source": [
        "class SimpleGCN(nn.Module):\n",
        "    \"\"\"Graph Convolutional Network - Simple and effective.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.classifier = nn.Linear(hidden_channels, num_classes)\n",
        "        self.p = 0.3\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, self.p, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, self.p, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        embeddings = F.relu(x)\n",
        "\n",
        "        logits = self.classifier(embeddings)\n",
        "        return logits, embeddings\n",
        "\n",
        "\n",
        "class SimpleGAT(nn.Module):\n",
        "    \"\"\"Graph Attention Network - Uses attention mechanism.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes, heads=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.3)\n",
        "        # self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=1, dropout=0.3)\n",
        "        self.conv3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, dropout=0.3)\n",
        "        self.classifier = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # x = self.conv2(x, edge_index)\n",
        "        # x = F.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        embeddings = F.relu(x)\n",
        "\n",
        "        logits = self.classifier(embeddings)\n",
        "        return logits, embeddings\n",
        "\n",
        "\n",
        "class SimpleSAGE(nn.Module):\n",
        "    \"\"\"GraphSAGE - Samples and aggregates neighbor features.\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.classifier = nn.Linear(hidden_channels, num_classes)\n",
        "        self.p = 0.2\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, self.p, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, self.p, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        embeddings = F.relu(x)\n",
        "\n",
        "        logits = self.classifier(embeddings)\n",
        "        return logits, embeddings\n",
        "\n",
        "\n",
        "print(\"✓ GNN architectures defined: GCN, GAT, SAGE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJMeqnwnRKSX"
      },
      "source": [
        "# CELL 4: Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDrVVgz3RRKU",
        "outputId": "07010014-836d-45ae-9f82-ff6a5b28fa96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Trainer class ready\n"
          ]
        }
      ],
      "source": [
        "class Trainer:\n",
        "    \"\"\"Handles model training and evaluation.\"\"\"\n",
        "\n",
        "    def __init__(self, model, device='cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [],\n",
        "            'val_ari': [], 'val_nmi': []\n",
        "        }\n",
        "\n",
        "    def train_epoch(self, loader, optimizer, criterion):\n",
        "        \"\"\"Single training epoch.\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for data in loader:\n",
        "            data = data.to(self.device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = self.model(data)\n",
        "            # Cast target labels to Long\n",
        "            loss = criterion(logits, data.y.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_nodes\n",
        "            correct += (logits.argmax(1) == data.y).sum().item()\n",
        "            total += data.num_nodes\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    def evaluate(self, loader, criterion):\n",
        "        \"\"\"Evaluate on validation/test set.\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                data = data.to(self.device)\n",
        "                logits, _ = self.model(data)\n",
        "                # Cast target labels to Long\n",
        "                loss = criterion(logits, data.y.long())\n",
        "\n",
        "                total_loss += loss.item() * data.num_nodes\n",
        "                pred = logits.argmax(1)\n",
        "                correct += (pred == data.y).sum().item()\n",
        "                total += data.num_nodes\n",
        "\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_labels.extend(data.y.cpu().numpy())\n",
        "\n",
        "        ari = adjusted_rand_score(all_labels, all_preds)\n",
        "        nmi = normalized_mutual_info_score(all_labels, all_preds)\n",
        "\n",
        "        return total_loss / total, correct / total, ari, nmi\n",
        "\n",
        "    def train(self, train_loader, val_loader, num_epochs=50, lr=0.01):\n",
        "        \"\"\"Full training loop with progress bar.\"\"\"\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        best_val_acc = 0\n",
        "\n",
        "        pbar = tqdm(range(num_epochs), desc=\"Training\")\n",
        "        for epoch in pbar:\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, optimizer, criterion)\n",
        "            val_loss, val_acc, val_ari, val_nmi = self.evaluate(val_loader, criterion)\n",
        "\n",
        "            # Record history\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_ari'].append(val_ari)\n",
        "            self.history['val_nmi'].append(val_nmi)\n",
        "\n",
        "            # Save best\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                self.best_state = self.model.state_dict()\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'train_acc': f'{train_acc:.3f}',\n",
        "                'val_acc': f'{val_acc:.3f}',\n",
        "                'val_ari': f'{val_ari:.3f}'\n",
        "            })\n",
        "\n",
        "        # Restore best model\n",
        "        self.model.load_state_dict(self.best_state)\n",
        "        return self.history\n",
        "\n",
        "print(\"✓ Trainer class ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN-KaWiChuA6"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNCGQu0n0-D-",
        "outputId": "4114c125-a649-4afe-d25a-213b29b6fcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration:\n",
            "  hidden_channels: 64\n",
            "  num_epochs: 1000\n",
            "  lr: 0.0008\n",
            "  batch_size: 32\n",
            "  weight_decay: 0.0005\n"
          ]
        }
      ],
      "source": [
        "CONFIG = {\n",
        "    'hidden_channels': 64,\n",
        "    'num_epochs': 1000,\n",
        "    'lr': 0.0008,\n",
        "    'batch_size': 32,\n",
        "    'weight_decay': 5e-4\n",
        "}\n",
        "\n",
        "print(\"\\nConfiguration:\")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpTszgL7RV3k"
      },
      "source": [
        "# Train All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "P2mbA3eF3KJY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import multiprocessing\n",
        "from torch_geometric.data import HeteroData\n",
        "from functools import partial\n",
        "import scipy.sparse\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "DFTdnO7X3Vef"
      },
      "outputs": [],
      "source": [
        "def load_facility_data(data_dir, split='train'):\n",
        "    \"\"\"加载设施选址问题的数据\"\"\"\n",
        "    data_path = os.path.join(data_dir, split)\n",
        "\n",
        "    all_files = glob.glob(os.path.join(data_path, '*.pt'))\n",
        "    dataset = []\n",
        "\n",
        "    for file_path in all_files:\n",
        "        # 加载异构图数据\n",
        "        # Set weights_only=False to handle PyTorch version compatibility\n",
        "        hetero_data = torch.load(file_path, weights_only=False)\n",
        "\n",
        "        # 创建同构图数据\n",
        "        # 使用variable节点的特征和标签\n",
        "        data = Data(\n",
        "            x=hetero_data['variable'].x,\n",
        "            y=hetero_data['variable'].y,\n",
        "            # 使用variable到constraint的边\n",
        "            edge_index=hetero_data['variable', 'in', 'constraint'].edge_index\n",
        "        )\n",
        "        dataset.append(data)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpm3VYdR3Yzh",
        "outputId": "cdbea813-52d4-4179-9f44-028837fe60d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ 训练集: 1200 个图\n",
            "✓ 验证集: 250 个图\n",
            "✓ 测试集: 250 个图\n"
          ]
        }
      ],
      "source": [
        "processed_data_dir = PROCESSED_DATA_DIR\n",
        "train_graphs = load_facility_data(processed_data_dir, 'train')\n",
        "val_graphs = load_facility_data(processed_data_dir, 'valid')\n",
        "test_graphs = load_facility_data(processed_data_dir,'test')\n",
        "\n",
        "print(f\"✓ 训练集: {len(train_graphs)} 个图\")\n",
        "print(f\"✓ 验证集: {len(val_graphs)} 个图\")\n",
        "print(f\"✓ 测试集: {len(test_graphs)} 个图\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unGrSFZLRdaU",
        "outputId": "e6e9658a-193a-4a22-b318-96445a1d8696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Input channels: 37\n",
            "✓ Output classes: 50\n"
          ]
        }
      ],
      "source": [
        "in_channels = train_graphs[0].x.shape[1]\n",
        "num_classes = len(torch.unique(train_graphs[0].y))\n",
        "print(f\"✓ Input channels: {in_channels}\")\n",
        "print(f\"✓ Output classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQqPyGeZ2W1i",
        "outputId": "c0c4c074-0da7-44ce-e985-f04824c6c221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ 数据加载器已创建\n",
            "  训练集批次数: 38\n",
            "  验证集批次数: 8\n",
            "  测试集批次数: 8\n"
          ]
        }
      ],
      "source": [
        "# 创建数据加载器\n",
        "train_loader = DataLoader(train_graphs, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_graphs, batch_size=CONFIG['batch_size'])\n",
        "test_loader = DataLoader(test_graphs, batch_size=CONFIG['batch_size'])\n",
        "\n",
        "print(f\"\\n✓ 数据加载器已创建\")\n",
        "print(f\"  训练集批次数: {len(train_loader)}\")\n",
        "print(f\"  验证集批次数: {len(val_loader)}\")\n",
        "print(f\"  测试集批次数: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asj_w1M-Rchl"
      },
      "source": [
        "# Initialize models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-JQ8CF1Riyb",
        "outputId": "1806374c-37bc-4fc8-ca3a-934ecabf1485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training GCN\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 105/1000 [02:19<19:43,  1.32s/it, train_acc=0.859, val_acc=0.862, val_ari=0.860]"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    'GCN': SimpleGCN(in_channels, CONFIG['hidden_channels'], num_classes),\n",
        "    'GAT': SimpleGAT(in_channels, CONFIG['hidden_channels'], num_classes),\n",
        "    'SAGE': SimpleSAGE(in_channels, CONFIG['hidden_channels'], num_classes),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    trainer = Trainer(model, device=device)\n",
        "    history = trainer.train(\n",
        "        train_loader, val_loader,\n",
        "        num_epochs=CONFIG['num_epochs'],\n",
        "        lr=CONFIG['lr']\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss, test_acc, test_ari, test_nmi = trainer.evaluate(test_loader, criterion)\n",
        "\n",
        "    results[name] = {\n",
        "        'test_acc': test_acc,\n",
        "        'test_ari': test_ari,\n",
        "        'test_nmi': test_nmi,\n",
        "        'history': history,\n",
        "        'trainer': trainer\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Test Results:\")\n",
        "    print(f\"  Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"  ARI: {test_ari:.4f}\")\n",
        "    print(f\"  NMI: {test_nmi:.4f}\")\n",
        "\n",
        "    # 保存最佳模型\n",
        "    model_save_path = os.path.join(MODELS_DIR, 'facilities', name)\n",
        "    os.makedirs(model_save_path, exist_ok=True)\n",
        "    torch.save(model.state_dict(), os.path.join(model_save_path, 'model.pt'))\n",
        "    print(f\"\\n模型已保存至 {model_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csqyp24tRkHI"
      },
      "source": [
        "# CELL 7: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-hImCFkRzYi"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL RESULTS COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Print comparison table\n",
        "print(f\"\\n{'Model':<10} {'Accuracy':<12} {'ARI':<12} {'NMI':<12}\")\n",
        "print(\"-\" * 60)\n",
        "for name, res in results.items():\n",
        "    print(f\"{name:<10} {res['test_acc']:<12.4f} {res['test_ari']:<12.4f} {res['test_nmi']:<12.4f}\")\n",
        "\n",
        "# Plot training curves for all models\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "fig.suptitle('Training Metrics Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics = [\n",
        "    ('train_loss', 'Training Loss'),\n",
        "    ('train_acc', 'Training Accuracy'),\n",
        "    ('val_loss', 'Validation Loss'),\n",
        "    ('val_acc', 'Validation Accuracy'),\n",
        "    ('val_ari', 'Validation ARI'),\n",
        "    ('val_nmi', 'Validation NMI')\n",
        "]\n",
        "\n",
        "for idx, (metric, title) in enumerate(metrics):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    for name, res in results.items():\n",
        "        ax.plot(res['history'][metric], label=name, linewidth=2)\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Bar chart comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "fig.suptitle('Test Set Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_bar = [\n",
        "    ('test_acc', 'Accuracy'),\n",
        "    ('test_ari', 'Adjusted Rand Index'),\n",
        "    ('test_nmi', 'Normalized Mutual Info')\n",
        "]\n",
        "\n",
        "for idx, (metric, title) in enumerate(metrics_bar):\n",
        "    ax = axes[idx]\n",
        "    values = [results[name][metric] for name in models.keys()]\n",
        "    bars = ax.bar(models.keys(), values, color=['#3b82f6', '#10b981', '#f59e0b'])\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "    ax.set_ylim(0, 1.0)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.save(PROJECT_ROOT)\n",
        "\n",
        "print(\"\\n✓ All visualizations complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seSYUpjwRpTO"
      },
      "source": [
        "# CELL 8: Analyze Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_1opooGPTOT"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DETAILED ANALYSIS OF BEST MODEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find best model\n",
        "best_model_name = max(results.keys(), key=lambda k: results[k]['test_ari'])\n",
        "best_trainer = results[best_model_name]['trainer']\n",
        "best_model = best_trainer.model\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Test ARI: {results[best_model_name]['test_ari']:.4f}\")\n",
        "\n",
        "# Get predictions and embeddings on test set\n",
        "best_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_embeddings = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        logits, embeddings = best_model(data)\n",
        "        all_preds.extend(logits.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(data.y.cpu().numpy())\n",
        "        all_embeddings.append(embeddings.cpu().numpy())\n",
        "\n",
        "all_embeddings = np.vstack(all_embeddings)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f'Cluster {i}' for i in range(CONFIG['num_clusters'])],\n",
        "            yticklabels=[f'Cluster {i}' for i in range(CONFIG['num_clusters'])])\n",
        "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Visualize embeddings with PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(all_embeddings)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
        "                     c=all_labels, cmap='viridis',\n",
        "                     s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "plt.colorbar(scatter, label='True Cluster')\n",
        "plt.title(f'Node Embeddings (PCA) - {best_model_name}', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Analysis complete!\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXPERIMENT FINISHED SUCCESSFULLY!\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}