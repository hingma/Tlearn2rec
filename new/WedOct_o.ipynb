{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZEps5dLb-sC",
        "outputId": "f44601ee-bbe7-4982-91ee-d6b24380a4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tlearn2rec'...\n",
            "remote: Enumerating objects: 13840, done.\u001b[K\n",
            "remote: Total 13840 (delta 0), reused 0 (delta 0), pack-reused 13840 (from 2)\u001b[K\n",
            "Receiving objects: 100% (13840/13840), 156.11 MiB | 14.63 MiB/s, done.\n",
            "Resolving deltas: 100% (8222/8222), done.\n",
            "Updating files: 100% (13723/13723), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hingma/Tlearn2rec.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV2u2dJ8c4qr",
        "outputId": "e77f874a-a193-4772-97d5-0153b48a0c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyomo in /usr/local/lib/python3.12/dist-packages (6.9.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from pyomo) (3.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.42.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torch_geometric pyomo networkx matplotlib wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uheJJEJWF9fh",
        "outputId": "f21578f4-b994-4084-f6a8-7b0db737f084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhlNpDSacV_c",
        "outputId": "a550e1e3-45ae-47e1-a32f-8bbe87ef1d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tlearn2rec/new\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Tlearn2rec/new/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYgudXgNCbra",
        "outputId": "d3b2a486-f4e0-4d25-f289-9c06fd233849"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCcJw_X_iDU7"
      },
      "outputs": [],
      "source": [
        "# import config\n",
        "# wandb.init(\n",
        "#     # set the wandb project where this run will be logged\n",
        "#     project=project,\n",
        "\n",
        "#     # track hyperparameters and run metadata\n",
        "#     config={\n",
        "#     \"learning_rate\": config.LR,\n",
        "#     \"architecture\": architecture,\n",
        "#     \"dataset\": dataset,\n",
        "#     \"epochs\": epochs,\n",
        "#     \"batch_size\": batch_size,\n",
        "#     \"momentum\": momentum\n",
        "#     }\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YFQJ-3IMEZ"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4fjEI0P8IO02"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "import config\n",
        "from datasets import build_loaders, load_karate\n",
        "from model import SimpleGCN, SimpleGAT, SimpleSAGE\n",
        "from visualize import plot_embeddings_and_clusters, plot_network_clusters, plot_training_loss, plot_validation_loss, plot_karate_score\n",
        "from cluster import GraphClustering, ClusteringEvaluator\n",
        "#\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc2wiUizJ5A7"
      },
      "source": [
        "## Wandb config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0rWkVXzIJ8kB"
      },
      "outputs": [],
      "source": [
        "project = 'MILP-GNN'\n",
        "learning_rate = config.LR\n",
        "epochs = config.MAX_EPOCHS\n",
        "# architecture ='CNN'\n",
        "# dataset = 'CIFAR-10'\n",
        "batch_size = config.BATCH_SIZE\n",
        "# momentum = 0.9\n",
        "log_freq = 1\n",
        "print_freq = 1\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBEYWLzuB27v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RvQhPqkB27v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwJORapRKV1R"
      },
      "source": [
        "## initialize the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsEx21NOKZVs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARc5TZh-IZHU"
      },
      "source": [
        "# Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "olP6TgB7IcK0"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, embeddings: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
        "        row, col = edge_index\n",
        "        pos = F.cosine_similarity(embeddings[row], embeddings[col], dim=1)\n",
        "        pos = torch.exp(pos / self.temperature)\n",
        "\n",
        "        num_nodes = embeddings.size(0)\n",
        "        neg_idx = torch.randint(0, num_nodes, (row.numel(),), device=embeddings.device)\n",
        "        neg = F.cosine_similarity(embeddings[col], embeddings[neg_idx], dim=1)\n",
        "        neg = torch.exp(neg / self.temperature)\n",
        "\n",
        "        loss = -torch.log(pos / (pos + neg + 1e-12)).mean()\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etCCGI8xIgRa"
      },
      "source": [
        "# Train for one epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NdQbcmghIlgG"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model: nn.Module, loader: DataLoader, criterion: nn.Module, optimizer: Optimizer, device: torch.device) -> float:\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        data = data.to(device)\n",
        "        # Debug shapes\n",
        "        if getattr(config, 'DEBUG_SHAPES', False) and not getattr(model, '_printed_train_batch', False):\n",
        "            print(f\"[train] batch x: {tuple(data.x.shape)} | edge_index: {tuple(data.edge_index.shape)}\")\n",
        "            if hasattr(data, 'batch') and data.batch is not None:\n",
        "                print(f\"[train] batch vector: {tuple(data.batch.shape)}\")\n",
        "            model._printed_train_batch = True\n",
        "        #===============================================\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = model(data)\n",
        "        edge_index = to_undirected(data.edge_index)\n",
        "        loss = criterion(embeddings, edge_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_graphs += 1\n",
        "        # log into wandb\n",
        "        if i % log_freq == log_freq - 1:\n",
        "            wandb.log({'train_loss': loss.item()})\n",
        "\n",
        "    return total_loss / max(1, total_graphs)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_loss(model: nn.Module, loader: DataLoader, criterion: nn.Module, device: torch.device) -> float:\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    for i, data in enumerate(loader,0):\n",
        "        data = data.to(device)\n",
        "        if getattr(config, 'DEBUG_SHAPES', False) and not getattr(model, '_printed_valid_batch', False):\n",
        "            print(f\"[valid] batch x: {tuple(data.x.shape)} | edge_index: {tuple(data.edge_index.shape)}\")\n",
        "            model._printed_valid_batch = True\n",
        "        embeddings = model(data)\n",
        "        loss = criterion(embeddings, to_undirected(data.edge_index))\n",
        "        total_loss += loss.item()\n",
        "        total_graphs += 1\n",
        "        # log into wandb\n",
        "        if i % log_freq == log_freq - 1:\n",
        "            wandb.log({'valid_loss': loss.item()})\n",
        "    return total_loss / max(1, total_graphs)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_on_karate(model: nn.Module, device: torch.device) -> float:\n",
        "    data = load_karate()\n",
        "    data = data.to(device)\n",
        "    # Ensure x has the expected feature dimension for the current model\n",
        "    in_channels_expected = getattr(model, 'conv1').in_channels\n",
        "    x = data.x\n",
        "    if x is None:\n",
        "        x = torch.eye(data.num_nodes, device=device)\n",
        "    if x.size(-1) < in_channels_expected:\n",
        "        # pad with zeros\n",
        "        pad = in_channels_expected - x.size(-1)\n",
        "        x = F.pad(x, (0, pad))\n",
        "    elif x.size(-1) > in_channels_expected:\n",
        "        # project with a fixed random matrix (deterministic by seed)\n",
        "        torch.manual_seed(config.SEED)\n",
        "        proj = torch.randn(x.size(-1), in_channels_expected, device=device)\n",
        "        x = x @ proj\n",
        "    data.x = x\n",
        "    embeddings = model(data)\n",
        "    # simple proxy: intra-edge cosine similarity mean (higher is better)\n",
        "    row, col = data.edge_index\n",
        "    sim = F.cosine_similarity(embeddings[row], embeddings[col], dim=1)\n",
        "    # log into wandb\n",
        "    wandb.log({'karate_score': sim.mean().item()})\n",
        "    return sim.mean().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6zfCkwmI0SI"
      },
      "source": [
        "# Clustering Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tNl-ip8XI3LU"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_clustering_pipeline(embedding: torch.Tensor,\n",
        "                            n_clusters: int | None = None,\n",
        "                            true_labels: torch.Tensor | None = None,\n",
        "                            use_gpu: bool = False):\n",
        "    \"\"\"Mirror the notebook pipeline: compute embeddings, run 3 clustering methods, evaluate.\n",
        "\n",
        "    Returns dict with embeddings, predicted labels per method, and evaluation metrics per method.\n",
        "    \"\"\"\n",
        "    if n_clusters is None and true_labels is not None:\n",
        "        unique = torch.unique(true_labels)\n",
        "        n_clusters = int(unique.numel())\n",
        "    if n_clusters is None:\n",
        "        n_clusters = 2\n",
        "\n",
        "    clusterer = GraphClustering(n_clusters=n_clusters, use_gpu=use_gpu)\n",
        "    evaluator = ClusteringEvaluator()\n",
        "\n",
        "    results_summary = {}\n",
        "    clustering_results = {}\n",
        "\n",
        "    # K-Means\n",
        "    try:\n",
        "        kmeans_labels, _ = clusterer.kmeans_clustering(embedding)\n",
        "        kmeans_results = evaluator.evaluate_clustering(true_labels, kmeans_labels, embedding)\n",
        "        # evaluator.print_results(kmeans_results, \"K-Means\")\n",
        "        results_summary['K-Means'] = kmeans_results\n",
        "        clustering_results['kmeans'] = kmeans_labels\n",
        "    except Exception as e:\n",
        "        print(f\"[clustering] K-Means failed: {e}\")\n",
        "\n",
        "    # Spectral\n",
        "    try:\n",
        "        spectral_labels, _ = clusterer.spectral_clustering(embedding)\n",
        "        spectral_results = evaluator.evaluate_clustering(true_labels, spectral_labels, embedding)\n",
        "        # evaluator.print_results(spectral_results, \"Spectral\")\n",
        "        results_summary['Spectral'] = spectral_results\n",
        "        clustering_results['spectral'] = spectral_labels\n",
        "    except Exception as e:\n",
        "        print(f\"[clustering] Spectral failed: {e}\")\n",
        "\n",
        "    # Hierarchical\n",
        "    try:\n",
        "        hierarchical_labels, _ = clusterer.hierarchical_clustering(embedding)\n",
        "        hierarchical_results = evaluator.evaluate_clustering(true_labels, hierarchical_labels, embedding)\n",
        "        # evaluator.print_results(hierarchical_results, \"Hierarchical\")\n",
        "        results_summary['Hierarchical'] = hierarchical_results\n",
        "        clustering_results['hierarchical'] = hierarchical_labels\n",
        "    except Exception as e:\n",
        "        print(f\"[clustering] Hierarchical failed: {e}\")\n",
        "\n",
        "    return {\n",
        "        'embeddings': embedding,\n",
        "        'clustering_results': clustering_results,\n",
        "        'evaluation_results': results_summary,\n",
        "    }\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_clustering_on_loader(model: nn.Module,\n",
        "                                  loader: DataLoader,\n",
        "                                  device: torch.device) -> None:\n",
        "    \"\"\"Evaluate clustering quality per-graph in a (possibly batched) loader and print averages.\n",
        "\n",
        "    - Uses true labels `y` when available to compute ARI/NMI; always computes internal metrics.\n",
        "    - Number of clusters is inferred from true labels when available; otherwise defaults to 2.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Aggregators per method -> metric -> list of values\n",
        "    agg: dict[str, dict[str, list[float]]] = {}\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        embeddings = model(batch)\n",
        "\n",
        "        # Determine graph ids in this batch (PyG provides `batch` vector when multiple graphs)\n",
        "        if hasattr(batch, 'batch') and batch.batch is not None:\n",
        "            graph_ids = torch.unique(batch.batch).tolist()\n",
        "        else:\n",
        "            graph_ids = [None]\n",
        "\n",
        "        for gid in graph_ids:\n",
        "            if gid is None:\n",
        "                node_mask = torch.ones(embeddings.size(0), dtype=torch.bool, device=device)\n",
        "            else:\n",
        "                node_mask = (batch.batch == gid)\n",
        "\n",
        "            emb_g = embeddings[node_mask]\n",
        "            y_g = batch.y[node_mask] if (hasattr(batch, 'y') and batch.y is not None) else None\n",
        "\n",
        "            if emb_g.size(0) < 2:\n",
        "                continue\n",
        "\n",
        "            n_clusters = int(torch.unique(y_g).numel()) if y_g is not None else 2\n",
        "\n",
        "            out = run_clustering_pipeline(embedding=emb_g,  # bypass model; we already have emb_g\n",
        "                                          n_clusters=n_clusters,\n",
        "                                          true_labels=y_g,\n",
        "                                          use_gpu=device.type == 'cuda')\n",
        "\n",
        "            # Collect metrics\n",
        "            for method_name, metrics in out['evaluation_results'].items():\n",
        "                if method_name not in agg:\n",
        "                    agg[method_name] = {k: [] for k in metrics.keys()}\n",
        "                for metric, value in metrics.items():\n",
        "                    if isinstance(value, float):\n",
        "                        agg[method_name][metric].append(value)\n",
        "\n",
        "    # Print averages\n",
        "    if not agg:\n",
        "        print(\"[clustering] No metrics collected.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n=== Clustering evaluation (averaged over validation graphs) ===\")\n",
        "    for method_name, metrics in agg.items():\n",
        "        print(f\"\\n-- {method_name} --\")\n",
        "        for metric, values in metrics.items():\n",
        "            if len(values) == 0:\n",
        "                continue\n",
        "            mean_val = sum(values) / len(values)\n",
        "            print(f\"{metric}: {mean_val:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL_lmD9fI9bz"
      },
      "source": [
        "# Main training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "O6bJcPQpB27w"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameter configurations to try\n",
        "project = \"MILP-GNN\"\n",
        "hyperparameter_configs = [\n",
        "    {'architecture': 'SimpleGCN', 'learning_rate': 0.0075, 'batch_size': 16, 'epochs': 100, 'optimizer': 'adam'},\n",
        "    {'architecture': 'SimpleGCN', 'learning_rate': 0.0125, 'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'},\n",
        "    {'architecture': 'SimpleGAT', 'learning_rate': 0.0075, 'batch_size': 16, 'epochs': 100, 'optimizer': 'adam'},\n",
        "    {'architecture': 'SimpleGAT', 'learning_rate': 0.0125, 'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'},\n",
        "    {'architecture': 'SimpleSAGE', 'learning_rate': 0.0075, 'batch_size': 16, 'epochs': 100, 'optimizer': 'adam'},\n",
        "    {'architecture': 'SimpleSAGE', 'learning_rate': 0.0125, 'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H61OtI8iB27x",
        "outputId": "2e49d17e-a183-48e1-91a4-9b1f6247fd1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[setup] inferred in_channels from dataset: 4\n",
            "[setup] sample x: (5024, 4), edge_index: (2, 189856)\n"
          ]
        }
      ],
      "source": [
        "train_loader, valid_loader = build_loaders(train_batch_size=batch_size, valid_batch_size=batch_size)\n",
        "# Infer in_channels from first training graph\n",
        "sample = next(iter(train_loader))\n",
        "in_channels = sample.x.size(-1)\n",
        "\n",
        "if getattr(config, 'DEBUG_SHAPES', False):\n",
        "    print(f\"[setup] inferred in_channels from dataset: {in_channels}\")\n",
        "    print(f\"[setup] sample x: {tuple(sample.x.shape)}, edge_index: {tuple(sample.edge_index.shape)}\")\n",
        "# ================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "d9B7a_5BB27x"
      },
      "outputs": [],
      "source": [
        "def run(params):\n",
        "    # Extract parameters\n",
        "    learning_rate = params.get('learning_rate', 0.01)\n",
        "    architecture = params.get('architecture', 'SimpleGCN')\n",
        "    batch_size = params.get('batch_size', 64)\n",
        "    epochs = params.get('epochs', 5)\n",
        "    momentum = params.get('momentum', 0.9)\n",
        "    optimizer_name = params.get('optimizer', 'adam')\n",
        "    # ================================\n",
        "    torch.manual_seed(config.SEED)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # ======= init wandb\n",
        "    wandb.init(project=project,\n",
        "        config=params,\n",
        "        reinit=True)  # Allow multiple runs in the same process)\n",
        "    # ======= load data ================================\n",
        "    train_loader, valid_loader = build_loaders(train_batch_size=batch_size, valid_batch_size=batch_size)\n",
        "    # ======= initialize model =========================\n",
        "    print(\"training{model.__class__.__name__}\")\n",
        "    if architecture == 'SimpleGCN':\n",
        "        model = SimpleGCN(in_channels=in_channels, hidden_channels=config.HIDDEN_DIM, embedding_dim=config.EMBED_DIM).to(device)\n",
        "    elif architecture == 'SimpleGAT':\n",
        "        model = SimpleGAT(in_channels=in_channels, hidden_channels=config.HIDDEN_DIM, embedding_dim=config.EMBED_DIM).to(device)\n",
        "    elif architecture == 'SimpleSAGE':\n",
        "        model = SimpleSAGE(in_channels=in_channels, hidden_channels=config.HIDDEN_DIM, embedding_dim=config.EMBED_DIM).to(device)\n",
        "    # ================================\n",
        "    optimizer = Adam(model.parameters(), lr=config.LR)\n",
        "    # ================================\n",
        "    criterion = ContrastiveLoss(temperature=config.TEMPERATURE)\n",
        "    # ================================\n",
        "    best_val = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_path = config.EXPERIMENT_DIR / f'best_{architecture}_with_{batch_size}_and_{learning_rate}.pt'\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    karate_scores = []\n",
        "    for epoch in range(1, config.MAX_EPOCHS + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss = eval_loss(model, valid_loader, criterion, device)\n",
        "        karate_score = eval_on_karate(model, device)\n",
        "        #\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        karate_scores.append(karate_score)\n",
        "        #\n",
        "        print(f\"Epoch {epoch:03d} | train {train_loss:.4f} | val {val_loss:.4f} | karate {karate_score:.4f}\")\n",
        "        #\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save({'state_dict': model.state_dict(), 'in_channels': in_channels}, best_path)\n",
        "\n",
        "    print(f\"Best {model.__class__.__name__} model saved to: {best_path}\")\n",
        "\n",
        "    plot_training_loss(train_losses)\n",
        "    plot_validation_loss(val_losses)\n",
        "    plot_karate_score(karate_scores)\n",
        "\n",
        "    # Finish the wandb run\n",
        "    wandb.finish()\n",
        "\n",
        "    # Clustering-based evaluation on validation set using ground-truth labels when available\n",
        "    # evaluate_clustering_on_loader(model, valid_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAQB-AfbB27x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "_SIgRTU-B27x",
        "outputId": "07ec7f13-f4d7-43ab-e1a7-145d627a84f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running params 1 of 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">elated-morning-5</strong> at: <a href='https://wandb.ai/moxintang-ucb/MILP-GNN/runs/o2fmmpzw' target=\"_blank\">https://wandb.ai/moxintang-ucb/MILP-GNN/runs/o2fmmpzw</a><br> View project at: <a href='https://wandb.ai/moxintang-ucb/MILP-GNN' target=\"_blank\">https://wandb.ai/moxintang-ucb/MILP-GNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251023_031446-o2fmmpzw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Tlearn2rec/new/wandb/run-20251023_031621-pok7n43p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/moxintang-ucb/MILP-GNN/runs/pok7n43p' target=\"_blank\">winter-plant-6</a></strong> to <a href='https://wandb.ai/moxintang-ucb/MILP-GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/moxintang-ucb/MILP-GNN' target=\"_blank\">https://wandb.ai/moxintang-ucb/MILP-GNN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/moxintang-ucb/MILP-GNN/runs/pok7n43p' target=\"_blank\">https://wandb.ai/moxintang-ucb/MILP-GNN/runs/pok7n43p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training{model.__class__.__name__}\n",
            "[train] batch x: (5024, 4) | edge_index: (2, 189856)\n",
            "[train] batch vector: (5024,)\n",
            "[SimpleGCN] conv1: in=4, out=64\n",
            "[SimpleGCN] input x: (5024, 4), edge_index: (2, 189856)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1658080086.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameter_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running params {i+1} of {len(hyperparameter_configs)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2419036437.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mkarate_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mkarate_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_on_karate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2655630671.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#===============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_undirected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Tlearn2rec/new/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[SimpleGCN] conv1: in={self.conv1.in_channels}, out={self.conv1.out_channels}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[SimpleGCN] input x: {tuple(x.shape)}, edge_index: {tuple(edge_index.shape)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'source_to_target'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "for i, params in enumerate(hyperparameter_configs):\n",
        "    print(f\"Running params {i+1} of {len(hyperparameter_configs)}\")\n",
        "    run(params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "ewTjQaOHJA4K",
        "outputId": "c6b81bdf-1011-43e9-91c8-d3b60e94f461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[setup] inferred in_channels from dataset: 4\n",
            "[setup] sample x: (6224, 4), edge_index: (2, 16966)\n",
            "training{model.__class__.__name__}\n",
            "[train] batch x: (4929, 4) | edge_index: (2, 13345)\n",
            "[train] batch vector: (4929,)\n",
            "[SimpleGCN] conv1: in=4, out=64\n",
            "[SimpleGCN] input x: (4929, 4), edge_index: (2, 13345)\n",
            "[SimpleGCN] conv2: in=64, out=64\n",
            "[SimpleGCN] after conv1: (4929, 64)\n",
            "[SimpleGCN] conv3: in=64, out=64\n",
            "[SimpleGCN] after conv2: (4929, 64)\n",
            "[SimpleGCN] embeddings: (4929, 64)\n"
          ]
        },
        {
          "ename": "Error",
          "evalue": "You must call wandb.init() before wandb.log()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3549979684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mkarate_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mkarate_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_on_karate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4196722638.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# log into wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlog_freq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
          ]
        }
      ],
      "source": [
        "# torch.manual_seed(config.SEED)\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# train_loader, valid_loader = build_loaders()\n",
        "\n",
        "# # Infer in_channels from first training graph\n",
        "# sample = next(iter(train_loader))\n",
        "# in_channels = sample.x.size(-1)\n",
        "\n",
        "# if getattr(config, 'DEBUG_SHAPES', False):\n",
        "#     print(f\"[setup] inferred in_channels from dataset: {in_channels}\")\n",
        "#     print(f\"[setup] sample x: {tuple(sample.x.shape)}, edge_index: {tuple(sample.edge_index.shape)}\")\n",
        "\n",
        "# for model in [SimpleGCN, SimpleGAT, SimpleSAGE]:\n",
        "#     print(\"training{model.__class__.__name__}\")\n",
        "#     model = model(in_channels=in_channels, hidden_channels=config.HIDDEN_DIM, embedding_dim=config.EMBED_DIM).to(device)\n",
        "#     optimizer = Adam(model.parameters(), lr=config.LR)\n",
        "#     criterion = ContrastiveLoss(temperature=config.TEMPERATURE)\n",
        "\n",
        "#     best_val = float('inf')\n",
        "#     epochs_no_improve = 0\n",
        "#     best_path = config.EXPERIMENT_DIR / f'best_{model.__class__.__name__}.pt'\n",
        "#     train_losses = []\n",
        "#     val_losses = []\n",
        "#     karate_scores = []\n",
        "#     for epoch in range(1, config.MAX_EPOCHS + 1):\n",
        "#         train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "#         val_loss = eval_loss(model, valid_loader, criterion, device)\n",
        "#         karate_score = eval_on_karate(model, device)\n",
        "#         #\n",
        "#         train_losses.append(train_loss)\n",
        "#         val_losses.append(val_loss)\n",
        "#         karate_scores.append(karate_score)\n",
        "#         #\n",
        "#         print(f\"Epoch {epoch:03d} | train {train_loss:.4f} | val {val_loss:.4f} | karate {karate_score:.4f}\")\n",
        "#         #\n",
        "#         if val_loss < best_val - 1e-6:\n",
        "#             best_val = val_loss\n",
        "#             epochs_no_improve = 0\n",
        "#             torch.save({'state_dict': model.state_dict(), 'in_channels': in_channels}, best_path)\n",
        "\n",
        "#     print(f\"Best {model.__class__.__name__} model saved to: {best_path}\")\n",
        "\n",
        "#     plot_training_loss(train_losses)\n",
        "#     plot_validation_loss(val_losses)\n",
        "#     plot_karate_score(karate_scores)\n",
        "\n",
        "#     # Clustering-based evaluation on validation set using ground-truth labels when available\n",
        "#     # evaluate_clustering_on_loader(model, valid_loader, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tlearn311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}